{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.sparse.linalg\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "###### Do not modify here ###### \n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = graph_def\n",
    "    #strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "###### Do not modify  here ######\n",
    "\n",
    "###### Implement Data Preprocess here ######\n",
    "\n",
    "def detect_outliers(X):\n",
    "    n, k = X.data.shape\n",
    "    means = np.array([np.mean(X.data[:,i]) for i in range(k)])\n",
    "    stddevs = np.array([np.std(X.data[:,i]) for i in range(k)])\n",
    "    lowerbounds = means - 2*stddevs\n",
    "    upperbounds = means + 2*stddevs\n",
    "    NoOutliers_x = []\n",
    "    NoOutliers_y = []\n",
    "    for i in range(n):\n",
    "        for j in range(k):\n",
    "            if X.data[i][j] > lowerbounds[j] and X.data[i][j] < upperbounds[j]:\n",
    "                if j == k-1:\n",
    "                    NoOutliers_x.append(X.data[i])\n",
    "                    NoOutliers_y.append(X.target[i])\n",
    "            else:\n",
    "                break\n",
    "    X.data = np.asarray(NoOutliers_x, dtype=np.float64)\n",
    "    X.target = np.asarray(NoOutliers_y, dtype=np.float64)\n",
    "    return X\n",
    "\n",
    "def features_normalize(X):\n",
    "    k = X.shape[1]\n",
    "    means = np.array([np.mean(X[:,i]) for i in range(k)])\n",
    "    stddevs = np.array([np.std(X[:,i]) for i in range(k)])\n",
    "    normalized = (X - means) / stddevs\n",
    "    return normalized\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# detect outliers\n",
    "housing = detect_outliers(housing)\n",
    "\n",
    "# feature normalization\n",
    "housing.data = features_normalize(housing.data)\n",
    "\n",
    "# assign ground-truth X, Y and add biases 1 to X\n",
    "n, k = housing.data.shape\n",
    "X = np.c_[np.ones((n,1)), housing.data]\n",
    "Y = housing.target.reshape(n,1)\n",
    "\n",
    "# split into training set and testing set\n",
    "X_train = tf.constant(X[:int(n*0.9)], dtype=tf.float32, name=\"X_train\")\n",
    "Y_train = tf.constant(Y[:int(n*0.9)], dtype=tf.float32, name=\"Y_train\")\n",
    "X_train_T = tf.transpose(X_train, name=\"X_train_T\")\n",
    "X_test = tf.constant(X[int(n*0.9):], dtype=tf.float32, name=\"X_test\")\n",
    "Y_test = tf.constant(Y[int(n*0.9):], dtype=tf.float32, name=\"Y_test\")\n",
    "\n",
    "# setup and initialize tf variables theta, Y_hat, and error rate.\n",
    "init = tf.global_variables_initializer()\n",
    "theta = tf.Variable(np.zeros((k+1,1), dtype=np.float32), name=\"theta\")\n",
    "Y_hat = tf.Variable(np.zeros((int(n*0.1),1), dtype=np.float32), name=\"Y_hat\")\n",
    "e = tf.Variable(0.0, name=\"error_rate\")\n",
    "\n",
    "# setup tf ops\n",
    "cal_theta = tf.assign(theta, tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(X_train_T,X_train)), X_train_T), Y_train))\n",
    "cal_Y_hat = tf.assign(Y_hat, tf.matmul(X_test, theta))\n",
    "cal_e = tf.assign(e, tf.reduce_mean(tf.divide(tf.abs(tf.subtract(Y_test, Y_hat)), Y_test)))\n",
    "\n",
    "\n",
    "###### Implement Data Preprocess here ######\n",
    "\n",
    "###### Start TF session ######\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(cal_theta)\n",
    "    sess.run(cal_Y_hat)\n",
    "    sess.run(cal_e)\n",
    "    print(\"theta:\", sess.run(theta))\n",
    "    print(\"Error rate:\", sess.run(e))\n",
    "\n",
    "    show_graph(tf.get_default_graph().as_graph_def())\n",
    "    '''\n",
    "    Graph Explanation:\n",
    "    It starts from a global initialization, which is a uniqie substructure that only contains a node.\n",
    "    Then, we calaulate theta through a series of computation, which is defined by normal equation.\n",
    "    In testing phase, Y_hat is predicted by X_test*theta. \n",
    "    Eventually, we evaluate error rate e by the mean of abs(Y_test-Y_hat)/Y_test.\n",
    "    '''\n",
    "###### Start TF session ######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
